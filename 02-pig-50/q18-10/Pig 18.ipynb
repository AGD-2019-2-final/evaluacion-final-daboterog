{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf input output\n",
    "!mkdir output\n",
    "%load_ext bigdata\n",
    "%pig_start\n",
    "%timeout 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted data.csv\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -rm data.csv\n",
    "!hadoop fs -put data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " data = LOAD 'data.csv' USING PigStorage(',')\n",
      "T); AS (f1:INT, f2:CHARARRAY, f3:CHARARRAY, f4:CHARARRAY, f5:CHARARRAY, f6:IN \n",
      " DUMP data;\n",
      "2020-01-28 01:53:53,940 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-28 01:53:54,102 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-01-28 01:53:54,106 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2020-01-28 01:53:54,116 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2020-01-28 01:53:54,447 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2020-01-28 01:53:54,455 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-28 01:53:54,479 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2020-01-28 01:53:54,578 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-01-28 01:53:54,604 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-01-28 01:53:54,672 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-01-28 01:53:54,797 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1580171142447_0061\n",
      "2020-01-28 01:53:54,935 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-01-28 01:53:55,076 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1580171142447_0061\n",
      "2020-01-28 01:53:55,112 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://c97dee5a7a29:8088/proxy/application_1580171142447_0061/\n",
      "2020-01-28 01:54:10,355 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-28 01:54:10,359 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-01-28 01:54:10,484 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-28 01:54:10,488 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-01-28 01:54:10,513 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-01-28 01:54:10,514 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-28 01:54:10,519 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-01-28 01:54:10,585 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-28 01:54:10,589 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-01-28 01:54:10,619 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-28 01:54:10,622 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-01-28 01:54:10,647 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-28 01:54:10,651 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-01-28 01:54:10,712 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(1,Vivian,Hamilton,1971-07-08,green,1)\n",
      "(2,Karen,Holcomb,1974-05-23,green,4)\n",
      "(3,Cody,Garrett,1973-04-22,orange,1)\n",
      "(4,Roth,Fry,1975-01-29,black,1)\n",
      "(5,Zoe,Conway,1974-07-03,blue,2)\n",
      "(6,Gretchen,Kinney,1974-10-18,viole,1)\n",
      "(7,Driscoll,Klein,1970-10-05,blue,5)\n",
      "(8,Karyn,Diaz,1969-02-24,red,1)\n",
      "(9,Merritt,Guy,1974-10-17,indigo,4)\n",
      "(10,Kylan,Sexton,1975-02-28,black,4)\n",
      "(11,Jordan,Estes,1969-12-07,indigo,4)\n",
      "(12,Hope,Coffey,1973-12-24,green,5)\n",
      "(13,Vivian,Crane,1970-08-27,gray,5)\n",
      "(14,Clio,Noel,1972-12-12,red,5)\n",
      "(15,Hope,Silva,1970-07-01,blue,5)\n",
      "(16,Ayanna,Jarvis,1974-02-11,orange,5)\n",
      "(17,Chanda,Boyer,1973-04-01,green,4)\n",
      "(18,Chadwick,Knight,1973-04-29,yellow,1)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "data = LOAD 'data.csv' USING PigStorage(',')\n",
    "    AS (f1:INT, f2:CHARARRAY, f3:CHARARRAY, f4:CHARARRAY, f5:CHARARRAY, f6:INT);\n",
    "DUMP data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a = FOREACH data GENERATE f3, f5;\n",
      " DUMP a;\n",
      "2020-01-28 01:54:11,019 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-28 01:54:11,133 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-28 01:54:11,153 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-01-28 01:54:11,164 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-01-28 01:54:11,190 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-01-28 01:54:11,224 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1580171142447_0062\n",
      "2020-01-28 01:54:11,227 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-01-28 01:54:11,256 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1580171142447_0062\n",
      "2020-01-28 01:54:11,260 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://c97dee5a7a29:8088/proxy/application_1580171142447_0062/\n",
      "2020-01-28 01:54:31,618 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-28 01:54:31,624 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-01-28 01:54:31,684 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-28 01:54:31,688 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-01-28 01:54:31,722 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-28 01:54:31,727 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-01-28 01:54:31,757 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-28 01:54:31,760 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-01-28 01:54:31,786 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-28 01:54:31,789 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-01-28 01:54:31,813 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-28 01:54:31,816 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-01-28 01:54:31,874 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(Hamilton,green)\n",
      "(Holcomb,green)\n",
      "(Garrett,orange)\n",
      "(Fry,black)\n",
      "(Conway,blue)\n",
      "(Kinney,viole)\n",
      "(Klein,blue)\n",
      "(Diaz,red)\n",
      "(Guy,indigo)\n",
      "(Sexton,black)\n",
      "(Estes,indigo)\n",
      "(Coffey,green)\n",
      "(Crane,gray)\n",
      "(Noel,red)\n",
      "(Silva,blue)\n",
      "(Jarvis,orange)\n",
      "(Boyer,green)\n",
      "(Knight,yellow)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "a = FOREACH data GENERATE f3, f5;\n",
    "DUMP a;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " b = FILTER a BY NOT f5 MATCHES 'blue', 'black';\n",
      "2020-01-28 01:54:31,959 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1200: <line 4, column 37>  mismatched input ',' expecting SEMI_COLON\n",
      "Details at logfile: /datalake/evaluacion-final-daboterog/02-pig-50/q18-10/pig_1580176426153.log\n",
      " DUMP b;\n",
      "2020-01-28 01:54:32,095 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1003: Unable to find an operator for alias b\n",
      "Details at logfile: /datalake/evaluacion-final-daboterog/02-pig-50/q18-10/pig_1580176426153.log\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "b = FILTER a BY NOT f5 MATCHES 'blue', 'black';\n",
    "DUMP b;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " STORE b INTO 'output' USING PigStorage(',');\n",
      "2020-01-28 01:54:32,167 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1200: Pig script failed to parse: <line 4, column 6> Undefined alias: b\n",
      "Details at logfile: /datalake/evaluacion-final-daboterog/02-pig-50/q18-10/pig_1580176426153.log\n",
      " fs -get output/ .\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "STORE b INTO 'output' USING PigStorage(',');\n",
    "fs -get output/ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
